# This file is the entry point to configure your own services.
# Files in the packages/ subdirectory configure your dependencies.

# Put parameters here that don't need to change on each machine where the app is deployed
# https://symfony.com/doc/current/best_practices.html#use-parameters-for-application-configuration

parameters:
    ai.llama.default_base_url: "http://localhost:8052"
    ai.llama_embed.default_base_url: "http://127.0.0.1:8059"

services:
    # default configuration for services in *this* file
    _defaults:
        autowire: true # Automatically injects dependencies in your services.
        autoconfigure: true # Automatically registers your services as commands, event subscribers, etc.

    # makes classes in src/ available to be used as services
    # this creates a service per class whose id is the fully-qualified class name
    App\:
        resource: "../src/"
        exclude:
            - "../src/DependencyInjection/"
            - "../src/Entity/"
            - "../src/Kernel.php"

    ai.platform.llama:
        class: Symfony\AI\Platform\Platform
        factory: ['App\Platform\LlamaCpp\PlatformFactory', "create"]
        arguments:
            $baseUrl: "%env(default:ai.llama.default_base_url:LLAMA_BASE_URL)%"
            $apiKey: "%env(default::LLAMA_API_KEY)%"
        tags:
            - { name: ai.platform, platform: llama }

    ai.platform.llama_embed:
        class: Symfony\AI\Platform\Platform
        factory: ['App\Platform\LlamaCpp\PlatformFactory', "create"]
        arguments:
            $baseUrl: "%env(default:ai.llama_embed.default_base_url:LLAMA_EMBED_BASE_URL)%"
            $apiKey: "%env(default::LLAMA_API_KEY)%"
        tags:
            - { name: ai.platform, platform: llama_embed }
